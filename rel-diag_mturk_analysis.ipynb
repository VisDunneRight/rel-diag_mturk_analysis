{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90163bd4-f66f-4d4d-a525-a8420532f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - are all requirements really needed? Maybe have been from prior SIGMOD'20 paper requirements (pip freeze > requirements.txt)\n",
    "# - making notebook trusted helped\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import re               # regular expression\n",
    "from resample import bootstrap as res_bootstrap\n",
    "from ast import literal_eval\n",
    "from scipy.stats import bootstrap as scipybootstrap\n",
    "from scipy.stats import gmean       # geometric mean\n",
    "\n",
    "import altair as alt\n",
    "# alt.renderers.enable('jupyterlab', embed_options={'renderer': 'svg'})             # uses SVG instead of PNG which creates problems on my MAC\n",
    "# Avoids writing all the data to the notebook or disk. \n",
    "# Note that this may not work on some cloud-based Jupyter notebook services.\n",
    "# alt.data_transformers.enable('data_server')                                        # prevents writing data into JSON file, and instead loads when needed for analysis. Done in order to save space. But does not work so easily\n",
    "\n",
    "# Set Jupyter and Pandas to show 3 decimal places\n",
    "# %precision 3\n",
    "# TODO: what is the interpretation of above line?\n",
    "\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "np.set_printoptions(precision=3)\n",
    "# np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})            # TODO: does not work for lists..\n",
    "def print(*args):\n",
    "    __builtins__.print(*(\"%.3f\" % a if isinstance(a, float) else a\n",
    "                         for a in args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b494be-346d-4312-a156-2502cc62b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a consistent, useful theme for Altair\n",
    "def theme_1(*args, **kwargs):\n",
    "    labelFont = 'CMU Serif'\n",
    "    labelFontSize = 12\n",
    "    labelFontWeight = 'normal'\n",
    "    markColor = '#82c6df'\n",
    "    headerFont = labelFont\n",
    "    headerFontWeight = 'bold'\n",
    "    headerFontSize = 12\n",
    "    titleFont = labelFont\n",
    "    titleFontWeight = 'bold'\n",
    "    titleFontSize = 14\n",
    "    \n",
    "    return {\n",
    "        'config': {\n",
    "            'background' : '#ffffff',\n",
    "            \n",
    "            'view': {\n",
    "                'height': 450,\n",
    "                'width': 700,\n",
    "            },\n",
    "\n",
    "            'title': {\n",
    "                'anchor': 'center',\n",
    "                'color': '#000000',\n",
    "                'font': titleFont,\n",
    "                'fontSize': titleFontSize,\n",
    "                'fontWeight': titleFontWeight,\n",
    "                'fontStyle': 'italic'\n",
    "            },\n",
    "\n",
    "            'arc': {'fill': markColor},\n",
    "            'area': {'fill': markColor},\n",
    "            'line': {\n",
    "                'stroke': markColor, \n",
    "                'strokeWidth': 2\n",
    "                    },\n",
    "            'path': {'stroke': markColor},\n",
    "            'rect': {'fill': markColor},\n",
    "            'shape': {'stroke': markColor},\n",
    "            'symbol': {\n",
    "                'fill': markColor, \n",
    "                'size': 30\n",
    "            },\n",
    "\n",
    "            'axis': {\n",
    "                'labelFont': labelFont,\n",
    "                'labelFontSize': labelFontSize,\n",
    "                'labelFontWeight': labelFontWeight,\n",
    "                'titleFont': titleFont,\n",
    "                'titleFontSize': titleFontSize,\n",
    "                'titleFontWeight': titleFontWeight\n",
    "            },\n",
    "\n",
    "            'axisX': {\n",
    "                #'labelAngle': 0,\n",
    "                #'labelPadding': 4,\n",
    "                'tickSize': 3,\n",
    "                'titleFont': headerFont,\n",
    "                'titleFontSize': headerFontSize,\n",
    "                'titleFontWeight': headerFontWeight,\n",
    "            },\n",
    "\n",
    "            'axisY': {\n",
    "                #'labelBaseline': 'middle',\n",
    "                #'maxExtent': 45,\n",
    "                #'minExtent': 45,\n",
    "                'tickSize': 2,\n",
    "                #'titleAlign': 'left',\n",
    "                #'titleAngle': 0,\n",
    "                #'titleX': -45,\n",
    "                #'titleY': -11\n",
    "                'titleFont': headerFont,\n",
    "                'titleFontSize': headerFontSize,\n",
    "                'titleFontWeight': headerFontWeight,\n",
    "            },\n",
    "            \n",
    "            'header': {\n",
    "                'labelFont': labelFont,\n",
    "                'labelFontSize': labelFontSize,\n",
    "                'labelFontWeight': labelFontWeight,\n",
    "                'titleFont': headerFont,\n",
    "                'titleFontSize': headerFontSize,\n",
    "                'titleFontWeight': headerFontWeight,\n",
    "            },           \n",
    "            \n",
    "            'legend': {\n",
    "                'labelFont': labelFont,\n",
    "                'labelFontSize': labelFontSize,\n",
    "                #'symbolType': 'square',\n",
    "                'titleFont': titleFont,\n",
    "                'titleFontSize': titleFontSize,\n",
    "                'titleFontWeight': titleFontWeight\n",
    "            },\n",
    "\n",
    "            'range': {\n",
    "                # any color scheme from https://vega.github.io/vega/docs/schemes/#categorical \n",
    "                # in an object with scheme attribute. Alternatively an array of hex colors e.g. \n",
    "                # ['#ec8431', '#829eb1', '#c89d29', '#3580b1', '#adc839', '#ab7fb4']\n",
    "                'category': {'scheme': 'tableau10'},\n",
    "                'diverging': {'scheme': 'purpleorange'},\n",
    "                'heatmap': {'scheme': 'blues'},\n",
    "                'ordinal': {'scheme': 'blues'},\n",
    "                'ramp': {'scheme': 'blues'},\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "alt.themes.register('theme_1', theme_1)\n",
    "alt.themes.enable('theme_1');\n",
    "\n",
    "## One of these themes would work too\n",
    "# alt.themes.enable('latimes')\n",
    "# alt.themes.enable('default')\n",
    "\n",
    "\n",
    "# Styling function for pandas dataframes that highlights values less than 0.05.\n",
    "# To be used with stat_sign_df.style.applymap()\n",
    "def color_df(val):\n",
    "    significant = True if (val < 0.05) else False\n",
    "    if significant:\n",
    "        return 'background-color: yellow; font-weight: bold'\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "# Bootstrap method, adapted from: http://www.jtrive.com/the-empirical-bootstrap-for-confidence-intervals-in-python.html\n",
    "# TODO: remove, better to use the existing scipy method noew imported that also allows 'BCa' instead of 'percentage' (below is percentage feshly implemented)\n",
    "# 'from scipy.stats import bootstrap as scipybootstrap'\n",
    "def bootstrap(data, n=3000, func=np.mean):\n",
    "    \"\"\"\n",
    "    Generate `n` bootstrap samples, evaluating `func`\n",
    "    at each resampling. `bootstrap` returns a function,\n",
    "    which can be called to obtain confidence intervals\n",
    "    of interest.\n",
    "    \"\"\"\n",
    "    simulations = list()\n",
    "    sample_size = len(data)\n",
    "    xbar_init = np.mean(data)\n",
    "    for c in range(n):\n",
    "        itersample = np.random.choice(data, size=sample_size, replace=True)\n",
    "        simulations.append(func(itersample))\n",
    "    simulations.sort()\n",
    "    def ci(p):\n",
    "        \"\"\"\n",
    "        Return 2-sided symmetric confidence interval specified\n",
    "        by p. p is a percentage (i.e. 95%, 90% etc.)\n",
    "        \"\"\"\n",
    "        u_pval = (1+p)/2.\n",
    "        l_pval = (1-u_pval)\n",
    "        l_indx = int(np.floor(n*l_pval))\n",
    "        u_indx = int(np.floor(n*u_pval))\n",
    "        return[simulations[l_indx],simulations[u_indx]]\n",
    "    return(ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60109a40-4d08-4bd6-90ed-a6788cfe728a",
   "metadata": {},
   "source": [
    "## Global Variables Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d96cd-4678-4d54-a8eb-d84cf3e14247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A set of constant global variables used throughout the notebook\n",
    "num_questions = 32\n",
    "modes = ['SQL', 'RD']\n",
    "mode_to_name = {0: 'SQL', 1: 'RD'}\n",
    "\n",
    "BOOTSTRAPCONFIDENCE = 0.95      # confidence level used for bootstrap\n",
    "BOOTSTRAPMETHOD = 'BCa'         # method used for bootstrap, appears to be better than the textbook version also available as 'percentage'\n",
    "BOOTSTRAPSAMPLES = 10000        # number of resamples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b86e6-d818-4a15-a5f4-9ca691e84fba",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385495ea-f2c9-4273-9cd9-4e2378417641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should point to our full study data when it is available\n",
    "filename = 'data/users-table-pilot.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df['pattern_order']= df['pattern_order'].apply(literal_eval)    # turn string to array\n",
    "df\n",
    "\n",
    "# TODO: what is \"current_page\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reformatting the dataframe to make later analysis easier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The following sequence reformats the data frame to have one question per row. That simplifies the later analysis.\n",
    "\n",
    "# reshape df (melt, pivot) to bring multiple question times (e.g. 'q7_time') per row into separate rows\n",
    "# https://towardsdatascience.com/wide-to-long-data-how-and-when-to-use-pandas-melt-stack-and-wide-to-long-7c1e0f462a98\n",
    "df2 = df.melt(id_vars=['worker_id', 'sequence_num', 'pattern_order',\n",
    "                       'q1', 'q2','q3', 'q4','q5', 'q6','q7', 'q8', 'q9', 'q10',\n",
    "                       'q11', 'q12','q13', 'q14','q15', 'q16','q17', 'q18', 'q19', 'q20',\n",
    "                       'q21', 'q22','q23', 'q24','q25', 'q26','q27', 'q28', 'q29', 'q30',\n",
    "                       'q31', 'q32'], value_vars=['q1_time', 'q2_time', 'q3_time', 'q4_time','q5_time', 'q6_time', 'q7_time', 'q8_time', 'q9_time', 'q10_time',\n",
    "                                                  'q11_time', 'q12_time', 'q13_time', 'q14_time', 'q15_time', 'q16_time', 'q17_time', 'q18_time', 'q19_time', 'q20_time',\n",
    "                                                  'q21_time', 'q22_time', 'q23_time', 'q24_time', 'q25_time', 'q26_time', 'q27_time', 'q28_time', 'q29_time', 'q30_time',\n",
    "                                                  'q31_time', 'q32_time'], var_name='question', value_name='time')\n",
    "\n",
    "# replace time in msec with sec in column 'time'\n",
    "df2['time'] = df2['time'] / 1000\n",
    "\n",
    "# replace question string 'q7_time' with number '7' in column 'question'\n",
    "new_column = []\n",
    "for values in df2['question']:\n",
    "    new_column.append(int(re.search(r'\\d+', values).group()))\n",
    "df2['question'] = new_column\n",
    "\n",
    "# choose the right pattern from the list 'pattern_order' and add ass column 'pattern\n",
    "new_column = []\n",
    "for (pattern_order_list, ind) in zip(df2['pattern_order'], df2['question']):\n",
    "    new_column.append(pattern_order_list[ind-1])\n",
    "df2['pattern'] = new_column\n",
    "\n",
    "# determine the 'mode' (SQL or RD) from 'sequence_num' and 'question'\n",
    "#   sequence_num = 0 means that the first question is shown in SQL, 1 means we start instead with RD. Then alternate between the two.\n",
    "#   Thus (sequence_num + question_num) % 2 == 1 means SQL\n",
    "#   Thus (sequence_num + question_num) % 2 == 0 means RD\n",
    "new_column = []\n",
    "for (sequence, question) in zip(df2['sequence_num'], df2['question']):\n",
    "    mode = 'SQL' if (sequence + question) % 2 == 1 else 'RD'\n",
    "    new_column.append(mode)\n",
    "df2['mode'] = new_column\n",
    "\n",
    "# determine the 'choice' (among the 4 patterns) made by the user for this question. Requires all the 32 question choices (e.g. 'q7') and index of the question at hand ('question')\n",
    "questionarray = df2[['q1', 'q2','q3', 'q4','q5', 'q6','q7', 'q8', 'q9', 'q10',\n",
    "                     'q11', 'q12','q13', 'q14','q15', 'q16','q17', 'q18', 'q19', 'q20',\n",
    "                     'q21', 'q22','q23', 'q24','q25', 'q26','q27', 'q28', 'q29', 'q30',\n",
    "                     'q31', 'q32']].to_numpy()\n",
    "questionindex = df2[[\"question\"]].to_numpy()\n",
    "\n",
    "new_array = np.take_along_axis(questionarray,questionindex-1,1)     # take the 'questionindex'-th entry from each row of teh questionarray (notice 1-index vs 0-indexin)\n",
    "df2['choice'] = new_array\n",
    "\n",
    "# determine whether the choice was correct by comparing the ground truth ('pattern') against the choice made ('choice'). Saved as 0/1 value in new column 'correct'\n",
    "new_column = []\n",
    "for (pattern, choice) in zip(df2['pattern'], df2['choice']):\n",
    "    correct = 1 if pattern == choice else 0\n",
    "    new_column.append(correct)\n",
    "df2['correct'] = new_column\n",
    "\n",
    "# sort by worker and question number, and reset the inde\n",
    "df2.sort_values(by=['worker_id', 'question'], inplace=True)\n",
    "df2.reset_index(drop=True, inplace=True)\n",
    "# df2\n",
    "\n",
    "# select only the relevant subset of columns\n",
    "df3 = df2[['worker_id', 'question', 'time', 'pattern', 'mode', 'choice', 'correct']]\n",
    "df3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df8 = df3.loc[df3['mode'] == 'SQL', df3['pattern'] == 1, ['time']]\n",
    "df8 = df3.query(\"mode=='SQL' and pattern==2\")['time']\n",
    "# df.query('Fee==25000')['Courses']\n",
    "display(df8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "f7e83386-4863-4160-afbf-524b385c143a",
   "metadata": {},
   "source": [
    "## Outline of the questions asked / analysis performed later\n",
    "\n",
    "### TODO: double-check the set of questions below, plus where the 90% confidence interval is calculated\n",
    "\n",
    "TIMING PER PARTICIPANT TOTAL\n",
    "1. per participant, calculate the mean time in seconds spent on RD (32/2=16 per participant, irrespective of correctness), and SQL, and their difference median(RD)-median(SQL)         [TODO: is mean here instead of median correct?]\n",
    "2. calculate the median of those differences across n participants (-4.81 sec, thus faster with RD)\n",
    "3. calculate the fraction of users who whose difference is < 0 (thus who were faster with RD)\n",
    "\n",
    "\n",
    "TODO: correct the numbering scheme with consistent indentation. I like to use continuous numbering\n",
    "\n",
    "\n",
    "TIMING PER PARTICIPANT 1st / 2nd half\n",
    "4. per participant, calculate the mean time over all questions answered in 1st half in RD (32/2/2=8), and SQL and in 2nd half.\n",
    "5. Calculate the relative improvement rate (in percentage) (1st-2nd)/1st for RD, and SQL, and their difference.\n",
    "\n",
    "TIMING ACROSS PARTICIPANTS\n",
    "6. take median over all questions and all users answered in SQL (32/2*13), or in QV (2 values)\n",
    "7. Calculate p-value for significance of difference\n",
    "\n",
    "TIMING PATTERNS ACROSS PARTICIPANTS\n",
    "8. Report the median time per pattern (4) across the two modes (2). Thus 8 values. Also report differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Answers to questions 1-3\n",
    "\n",
    "# for each worker, calculate mean and median for both modes\n",
    "dfq1 = df3.groupby(['worker_id', 'mode']).time.agg(['mean', 'median'])\n",
    "\n",
    "# pivot to have one row per worker\n",
    "dfq1 = pd.pivot_table(dfq1, values=['mean', 'median'], index=['worker_id'], columns=['mode'])\n",
    "\n",
    "# add the differences between means and medians cross the modes\n",
    "dfq1['diff mean'] = dfq1['mean','RD'] - dfq1['mean','SQL']\n",
    "dfq1['diff median'] = dfq1['median','RD'] - dfq1['median','SQL']\n",
    "dfq1['ratio mean'] = dfq1['mean','RD'] / dfq1['mean','SQL']\n",
    "dfq1['ratio median'] = dfq1['mean','RD'] / dfq1['median','SQL']\n",
    "display(dfq1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Answers to questions 1-2\n",
    "\n",
    "data = dfq1['diff mean']\n",
    "print('mean of mean differences = ', np.mean(data))\n",
    "# ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method=BOOTSTRAPMETHOD, axis=0).confidence_interval        #convert array to sequence\n",
    "# print('95% CI = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='percentile', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (percentile) = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='BCa', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (BCa) = ', np.array([ci.low, ci.high]))\n",
    "print()\n",
    "\n",
    "data = dfq1['diff mean']\n",
    "print('median of mean differences = ', np.median(data))\n",
    "# ci = scipybootstrap((data,), statistic=np.median, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method=BOOTSTRAPMETHOD, axis=0).confidence_interval        #convert array to sequence\n",
    "# print('95% CI = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.median, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='percentile', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (percentile) = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.median, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='BCa', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (BCa) = ', np.array([ci.low, ci.high]))\n",
    "print(\"   Notice that 'BCa' is identical to 'percentile' for median!! \")\n",
    "print()\n",
    "\n",
    "data = dfq1['diff median']\n",
    "print('median of median differences = ', np.median(data))\n",
    "# ci = scipybootstrap((data,), statistic=np.median, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method=BOOTSTRAPMETHOD, axis=0).confidence_interval        #convert array to sequence\n",
    "# print('95% CI = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.median, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='percentile', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (percentile) = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.median, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='BCa', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (BCa) = ', np.array([ci.low, ci.high]))\n",
    "print()\n",
    "\n",
    "data = dfq1['diff median']\n",
    "print('mean of median differences = ', np.mean(data))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='percentile', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (percentile) = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='BCa', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (BCa) = ', np.array([ci.low, ci.high]))\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "print('mean of mean RD = ', np.mean(dfq1['mean', 'RD']))\n",
    "print('mean of mean SQL = ', np.mean(dfq1['mean', 'SQL']))\n",
    "print('median of mean RD = ', np.median(dfq1['mean', 'RD']))\n",
    "print('median of mean SQL = ', np.median(dfq1['mean', 'SQL']))\n",
    "print('mean of median RD = ', np.mean(dfq1['median', 'RD']))\n",
    "print('mean of median SQL = ', np.mean(dfq1['median', 'SQL']))\n",
    "print('median of median RD = ', np.median(dfq1['median', 'RD']))\n",
    "print('median of median SQL = ', np.median(dfq1['median', 'SQL']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Relative improvements from RD over SQL\n",
    "\n",
    "data = dfq1['ratio mean']\n",
    "print('mean of ratio mean differences = ', np.mean(data))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='percentile', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (percentile) = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='BCa', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (BCa) = ', np.array([ci.low, ci.high]))\n",
    "print()\n",
    "\n",
    "data = dfq1['ratio mean']\n",
    "print('median of ratio mean differences = ', np.median(data))\n",
    "ci = scipybootstrap((data,), statistic=np.median, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method=BOOTSTRAPMETHOD, axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI = ', np.array([ci.low, ci.high]))\n",
    "print()\n",
    "\n",
    "data = dfq1['ratio median']\n",
    "print('median of ratio median differences = ', np.median(data))\n",
    "ci = scipybootstrap((data,), statistic=np.median, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method=BOOTSTRAPMETHOD, axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI = ', np.array([ci.low, ci.high]))\n",
    "print()\n",
    "\n",
    "data = dfq1['ratio median']\n",
    "print('mean of ratio median differences = ', np.mean(data))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='percentile', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (percentile) = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='BCa', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (BCa) = ', np.array([ci.low, ci.high]))\n",
    "print()\n",
    "\n",
    "data = dfq1['ratio mean']\n",
    "print('geometric mean of ratio mean differences = ', gmean(data))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='percentile', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (percentile) = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='BCa', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (BCa) = ', np.array([ci.low, ci.high]))\n",
    "print('as comparison: ratio of their means:', np.mean(dfq1['mean', 'RD']) / np.mean(dfq1['mean', 'SQL']))\n",
    "\n",
    "print()\n",
    "\n",
    "data = dfq1['ratio median']\n",
    "print('geometric mean of ratio median differences = ', gmean(data))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='percentile', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (percentile) = ', np.array([ci.low, ci.high]))\n",
    "ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method='BCa', axis=0).confidence_interval        #convert array to sequence\n",
    "print('95% CI (BCa) = ', np.array([ci.low, ci.high]))\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Answers to question 3: Percentage being faster with RD\n",
    "\n",
    "fastermean = np.sum(dfq1['diff mean']<0)/len(dfq1)\n",
    "print('Percentage of users who were faster with RD via means = ', fastermean)\n",
    "fastermedian = np.sum(dfq1['diff median']<0)/len(dfq1)\n",
    "print('Percentage of users who were faster with RD via medians = ', fastermedian)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysing improvements from 1st to 2nd half per mode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for each worker, calculate mean and median for both modes\n",
    "dfq2 = df3.groupby(['worker_id', 'mode', df3['question']> 16]).time.agg(['median', 'mean'])         # TODO: it would be nicer to replace FALSE with 1st half and TRUE with 2nd half\n",
    "    # dfq2.replace(False, '1st half')\n",
    "    # dfq2['half'] = '2nd half' if dfq2['question'] == True else '1st half'\n",
    "\n",
    "# pivot to have one row per worker\n",
    "dfq2 = pd.pivot_table(dfq2, values=['mean', 'median'], index=['worker_id'], columns=['question', 'mode'])\n",
    "\n",
    "# add the relative improvements between 1st half (FALSE) and 2nd half (TRUE) per mode\n",
    "dfq2['improve mean RD'] = (dfq2['mean', True, 'RD'] - dfq2['mean', False, 'RD']) / dfq2['mean', False, 'RD']\n",
    "dfq2['improve mean SQL'] = (dfq2['mean', True, 'SQL'] - dfq2['mean', False, 'SQL']) / dfq2['mean', False, 'SQL']\n",
    "dfq2['improve median RD'] = (dfq2['median', True, 'RD'] - dfq2['median', False, 'RD']) / dfq2['median', False, 'RD']\n",
    "dfq2['improve median SQL'] = (dfq2['median', True, 'SQL'] - dfq2['median', False, 'SQL']) / dfq2['median', False, 'SQL']\n",
    "display(dfq2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# relative improvements from 1st to 2nd half\n",
    "print('Relative improvements from 1st to 2nd half per mode')\n",
    "print('[I now think this should be calculated differently, with some paired bootstrap]')\n",
    "\n",
    "print(\"Suggested statistics (also from SIGMOD'20): median of mean differences:\")\n",
    "medianmeanRD = np.median(dfq2['improve mean RD'])\n",
    "print('median of mean improvements RD = ', medianmeanRD)\n",
    "medianmeanSQL = np.median(dfq2['improve mean SQL'])\n",
    "print('median of mean improvements SQL = ', medianmeanSQL)\n",
    "print('[I now think this should be calculated as follows]')\n",
    "print('Ratio of medians for RD = ', (np.median(dfq2['mean', True, 'RD']) - np.median(dfq2['mean', False, 'RD'])) / np.median(dfq2['mean', False, 'RD']))\n",
    "print('Ratio of medians for SQL = ', (np.median(dfq2['mean', True, 'SQL']) - np.median(dfq2['mean', False, 'SQL'])) / np.median(dfq2['mean', False, 'SQL']))\n",
    "print()\n",
    "\n",
    "print(\"Other non-suggested statistics:\")\n",
    "meanmeanRD = np.mean(dfq2['improve mean RD'])\n",
    "print('mean of mean improvements RD = ', meanmeanRD)\n",
    "meanmeanSQL = np.mean(dfq2['improve mean SQL'])\n",
    "print('mean of mean improvements SQL = ', meanmeanSQL)\n",
    "medianmedianRD = np.median(dfq2['improve median RD'])\n",
    "print('median of median improvements RD = ', medianmedianRD)\n",
    "medianmedianSQL = np.median(dfq2['improve median SQL'])\n",
    "print('median of median improvements SQL = ', medianmedianSQL)\n",
    "\n",
    "# TODO: what is here the right statistics and what is here the right confidence interval (perhaps on the differences?)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Are relative improvements of RD over SQL constant across the two halfs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# add the percentage improvements from SQL to RD per 1st and 2nd half\n",
    "dfq2['perc mean 1st'] = (dfq2['mean', False, 'RD'] - dfq2['mean', False, 'SQL']) / dfq2['mean', False, 'SQL']\n",
    "dfq2['perc median 1st'] = (dfq2['median', False, 'RD'] - dfq2['median',False, 'SQL']) / dfq2['median',False, 'SQL']\n",
    "dfq2['perc mean 2nd'] = (dfq2['mean', True, 'RD'] - dfq2['mean', True, 'SQL']) / dfq2['mean', True, 'SQL']\n",
    "dfq2['perc median 2nd'] = (dfq2['median', True, 'RD'] - dfq2['median',True, 'SQL']) / dfq2['median',True, 'SQL']\n",
    "\n",
    "display(dfq2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# relative improvements of RD over SQL in 1st and 2nd half\n",
    "print('Relative improvements of RD over SQL in 1st and 2nd half')\n",
    "\n",
    "data = dfq2['perc mean 1st']\n",
    "print('mean of percentage mean differences 1st = ', np.mean(data))\n",
    "data = dfq2['perc mean 2nd']\n",
    "print('mean of percentage mean differences 2nd = ', np.mean(data))\n",
    "data = dfq2['perc median 1st']\n",
    "print('mean of percentage median differences 1st = ', np.mean(data))\n",
    "data = dfq2['perc median 2nd']\n",
    "print('mean of percentage median differences 2nd = ', np.mean(data))\n",
    "print()\n",
    "data = dfq2['perc mean 1st']\n",
    "print('median of percentage mean differences 1st = ', np.median(data))\n",
    "data = dfq2['perc mean 2nd']\n",
    "print('median of percentage mean differences 2nd = ', np.median(data))\n",
    "data = dfq2['perc median 1st']\n",
    "print('median of percentage median differences 1st = ', np.median(data))\n",
    "data = dfq2['perc median 2nd']\n",
    "print('median of percentage median differences 2nd = ', np.median(data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Statistics per mode across participants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for each worker, calculate mean and median for both modes\n",
    "dfq3 = df3.groupby(['mode']).time.agg(['median', 'mean'])\n",
    "display(dfq3)\n",
    "\n",
    "print(\"Suggested statistics:\")\n",
    "for j in ('RD', 'SQL'):\n",
    "    data = df3.query(\"mode=='{}'\".format(j))['time']\n",
    "    print('median of {} = '.format(j), np.median(data))\n",
    "    ci = scipybootstrap((data,), statistic=np.median, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method=BOOTSTRAPMETHOD, axis=0).confidence_interval        #convert array to sequence\n",
    "    print('95% CI = ', np.array([ci.low, ci.high]))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Other statistics:\")\n",
    "for j in ('RD', 'SQL'):\n",
    "    data = df3.query(\"mode=='{}'\".format(j))['time']\n",
    "    print('mean of {} = '.format(j), np.mean(data))\n",
    "    ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method=BOOTSTRAPMETHOD, axis=0).confidence_interval        #convert array to sequence\n",
    "    print('95% CI = ', np.array([ci.low, ci.high]))\n",
    "print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Statistics per mode and pattern across participants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for each worker, calculate mean and median for both modes, then pivot the table\n",
    "dfq4 = df3.groupby(['mode', 'pattern']).time.agg(['median', 'mean'])\n",
    "dfq4 = pd.pivot_table(dfq4, values=['median', 'mean'], index=['pattern'], columns=['mode'])\n",
    "display(dfq4)\n",
    "\n",
    "print(\"Suggested statistics:\")\n",
    "for i in range(1, 5):\n",
    "    for j in ('RD', 'SQL'):\n",
    "        data = df3.query(\"mode=='{}' and pattern=={}\".format(j, i))['time']\n",
    "        print('pattern {} median of {} = '.format(i, j), np.median(data))\n",
    "        ci = scipybootstrap((data,), statistic=np.median, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method=BOOTSTRAPMETHOD, axis=0).confidence_interval        #convert array to sequence\n",
    "        print('95% CI = ', np.array([ci.low, ci.high]))\n",
    "    print()\n",
    "\n",
    "print(\"Non-recommended statistics:\")\n",
    "for i in range(1, 5):\n",
    "    for j in ('RD', 'SQL'):\n",
    "        data = df3.query(\"mode=='{}' and pattern=={}\".format(j, i))['time']\n",
    "        print('pattern {} mean of {} = '.format(i, j), np.mean(data))\n",
    "        ci = scipybootstrap((data,), statistic=np.mean, n_resamples=BOOTSTRAPSAMPLES, confidence_level=BOOTSTRAPCONFIDENCE, method=BOOTSTRAPMETHOD, axis=0).confidence_interval        #convert array to sequence\n",
    "        print('95% CI = ', np.array([ci.low, ci.high]))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# --- everything below is out for now ---\n",
    "\n",
    "\n",
    "\n",
    "CORRECTNESS (to be done later)\n",
    "1. We similarly computed the proportion of correct responses for each mode and their difference, as well as the proportion of correct responses for each mode on the first and second halves and the the difference of the two for each mode.\n",
    "\n",
    "Then, across all participants, we calculated the median time difference and mean difference in proportion of correct responses. [TODO: explain]\n",
    "??? We also computed the overall mean rate of improvement and mean difference in correct responses between the first and second halves. [TODO: details]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9519d79-c7e1-4437-8f86-1f5b0f1045ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_user(user):\n",
    "    incorrect_sql = []\n",
    "    incorrect_rd = []  \n",
    "    times_sql = []\n",
    "    times_rd = []\n",
    "\n",
    "\n",
    "    for i in range(0, num_questions):\n",
    "        one_indexed_q_num = i + 1\n",
    "        q_col = \"q\" + str(one_indexed_q_num)\n",
    "        q_time_col = q_col + \"_time\"\n",
    "\n",
    "        user_answer = user[q_col]\n",
    "        user_time = user[q_time_col] / 1000 # ms to s\n",
    "        answer = user['pattern_order'][i]\n",
    "\n",
    "        incorrect_int = 1 if user_answer != answer else 0\n",
    "        if (user['sequence_num'] + one_indexed_q_num) % 2 == 1:\n",
    "            incorrect_sql.append(incorrect_int)\n",
    "            times_sql.append(user_time)\n",
    "        else:\n",
    "            incorrect_rd.append(incorrect_int)\n",
    "            times_rd.append(user_time)\n",
    "            \n",
    "    num_each_mode = int(num_questions / 2)\n",
    "    halfway = int(num_each_mode / 2)\n",
    "\n",
    "    # CORRECTNESS\n",
    "\n",
    "    incorrect_sql_proportion = np.sum(incorrect_sql) / num_each_mode\n",
    "    incorrect_rd_proportion = np.sum(incorrect_rd) / num_each_mode\n",
    "    diff_incorrect_proportion = incorrect_rd_proportion - incorrect_sql_proportion\n",
    "    \n",
    "    first_incorrect_sql_proportion = np.sum(incorrect_sql[0:halfway]) / (num_each_mode / 2)\n",
    "    first_incorrect_rd_proportion = np.sum(incorrect_rd[0:halfway]) / (num_each_mode / 2)\n",
    "    first_diff_incorrect_proportion = first_incorrect_rd_proportion - first_incorrect_sql_proportion\n",
    "                                                    \n",
    "    second_incorrect_sql_proportion = np.sum(incorrect_sql[halfway:num_questions]) / (num_each_mode / 2)\n",
    "    second_incorrect_rd_proportion = np.sum(incorrect_rd[halfway:num_questions]) / (num_each_mode / 2)\n",
    "    second_diff_incorrect_proportion = second_incorrect_rd_proportion - second_incorrect_sql_proportion\n",
    "\n",
    "    incorrectness_improvement_sql = first_incorrect_sql_proportion - second_incorrect_sql_proportion\n",
    "    incorrectness_improvement_rd = first_incorrect_rd_proportion - second_incorrect_rd_proportion\n",
    "    diff_incorrectness_improvement = incorrectness_improvement_rd - incorrectness_improvement_sql\n",
    "\n",
    "    # TIMING\n",
    "\n",
    "    median_sql_time = np.median(times_sql)                          # TODO: why median instead of mean per participant (mean is what we used in SIGMOD'20)\n",
    "    median_rd_time = np.median(times_rd)\n",
    "    diff_time = median_rd_time - median_sql_time\n",
    "\n",
    "\n",
    "    first_median_sql_time = np.median(times_sql[0:halfway])\n",
    "    first_median_rd_time = np.median(times_rd[0:halfway])\n",
    "    first_diff_time = first_median_rd_time - first_median_sql_time\n",
    "    \n",
    "    second_median_sql_time = np.median(times_sql[halfway:num_questions])\n",
    "    second_median_rd_time = np.median(times_rd[halfway:num_questions])\n",
    "    second_diff_time = second_median_rd_time - second_median_sql_time\n",
    "    \n",
    "    time_improvement_sql = (first_median_sql_time - second_median_sql_time) / first_median_sql_time\n",
    "    time_improvement_rd = (first_median_rd_time - second_median_rd_time) / first_median_rd_time\n",
    "    diff_time_improvement = time_improvement_rd - time_improvement_sql\n",
    "\n",
    "\n",
    "    return {\n",
    "        'incorrect_sql_proportion' : incorrect_sql_proportion,\n",
    "        'incorrect_rd_proportion' : incorrect_rd_proportion,\n",
    "        'diff_incorrect_proportion' : diff_incorrect_proportion,        \n",
    "\n",
    "        'first_incorrect_sql_proportion' : first_incorrect_sql_proportion,\n",
    "        'first_incorrect_rd_proportion' : first_incorrect_rd_proportion,\n",
    "        'first_diff_incorrect_proportion' : first_diff_incorrect_proportion,\n",
    "        'second_incorrect_sql_proportion' : second_incorrect_sql_proportion,\n",
    "        'second_incorrect_rd_proportion' : second_incorrect_rd_proportion,\n",
    "        'second_diff_incorrect_proportion' : second_diff_incorrect_proportion,\n",
    "        \n",
    "        'median_sql_time' : median_sql_time,\n",
    "        'median_rd_time' : median_rd_time,\n",
    "        'diff_time' : diff_time,\n",
    "        \n",
    "        'first_median_sql_time' : first_median_sql_time,\n",
    "        'first_median_rd_time' : first_median_rd_time,\n",
    "        'first_diff_time' : first_diff_time,\n",
    "        'second_median_sql_time' : second_median_sql_time,\n",
    "        'second_median_rd_time' : second_median_rd_time,\n",
    "        'second_diff_time' : second_diff_time,\n",
    "        \n",
    "        'time_improvement_sql' : time_improvement_sql,\n",
    "        'time_improvement_rd' : time_improvement_rd,\n",
    "        'diff_time_improvement' : diff_time_improvement,\n",
    "        'incorrectness_improvement_sql' : incorrectness_improvement_sql,\n",
    "        'incorrectness_improvement_rd' : incorrectness_improvement_rd,\n",
    "        'diff_incorrectness_improvement' : diff_incorrectness_improvement\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9eb8ea-9eba-499c-9293-ed323d9492a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_participant_df_stats = df.apply(lambda row: compute_per_user(row), axis='columns', result_type='expand')\n",
    "per_participant_df = pd.concat([df, per_participant_df_stats], axis='columns')\n",
    "per_participant_df\n",
    "\n",
    "\n",
    "per_participant_df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3c75d-4197-4de1-835c-086c97336b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(per_participant_df['median_sql_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.median(per_participant_df['median_rd_time'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.median(per_participant_df['diff_time'])\n",
    "\n",
    "# alt.Chart(per_participant_df['diff_time']).mark_point().encode(\n",
    "#     x = 'median(diff_time:Q)'\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.median(per_participant_df['diff_incorrect_proportion'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a8e5c-8d66-4773-ab3b-eab05f409539",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_data = per_participant_df[['diff_time', 'diff_incorrect_proportion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b7de27-75ca-4284-8219-8dae0fb18381",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(alt_data).mark_tick().encode(\n",
    "    x='diff_time:Q'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: ALTAIR not workin"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "3e2ec8db-b628-4c02-9680-c45f53013517",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "alt.Chart(alt_data).mark_tick().encode(\n",
    "    x='diff_incorrect_proportion:Q'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c30d5-c78d-4535-ba2c-8256f0c98f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(alt_data).transform_density(\n",
    "    'diff_time',\n",
    "    as_=['diff_time', 'density'],\n",
    "    extent=[np.min(alt_data['diff_time']), np.max(alt_data['diff_time'])]\n",
    ").mark_area(orient='vertical').encode(\n",
    "    x=alt.X(\n",
    "        'diff_time:Q',\n",
    "        title=None\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        'density:Q',\n",
    "        stack='center',\n",
    "        impute=None,\n",
    "        title=None,\n",
    "        axis=alt.Axis(labels=False, values=[0],grid=False, ticks=True),\n",
    "    )\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=100,\n",
    "    title='Δ median time per question (Diagrams − SQL)'\n",
    ").configure_facet(\n",
    "    spacing=0\n",
    ").configure_view(\n",
    "    stroke=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe82269a-46f4-42d3-bfd6-cfa6052fa270",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(alt_data).transform_density(\n",
    "    'diff_incorrect_proportion',\n",
    "    as_=['diff_incorrect_proportion', 'density'],\n",
    "    extent=[np.min(alt_data['diff_incorrect_proportion']), np.max(alt_data['diff_incorrect_proportion'])]\n",
    ").mark_area(orient='vertical').encode(\n",
    "    x=alt.X(\n",
    "        'diff_incorrect_proportion:Q',\n",
    "        title=None,\n",
    "    ),\n",
    "    y=alt.Y(\n",
    "        'density:Q',\n",
    "        stack='center',\n",
    "        impute=None,\n",
    "        title=None,\n",
    "        axis=alt.Axis(labels=False, values=[0],grid=False, ticks=True),\n",
    "    )\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=60,\n",
    "    title='Δ percent errors (Diagrams − SQL)'\n",
    ").configure_facet(\n",
    "    spacing=0\n",
    ").configure_view(\n",
    "    stroke=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb13837f-1b5f-4d8f-b054-f7819e81949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtions used to calculate the confidence intervals and construct the graphs\n",
    "\n",
    "# Returns as a dataframe the differrence of QV and Both modes from SQL together with their bca confidence intervals for a given metric.\n",
    "def get_conf_interval_bca(values_per_mode, mode, column_list):\n",
    "    \n",
    "    values_per_with_bca_conf_intervals = {'value': [], 'mode': column_list, 'conf_interval_delta_from_value': []}\n",
    "    \n",
    "    if mode == 'median':\n",
    "        function = np.median\n",
    "    elif mode == 'gmean':\n",
    "        function = sc.stats.gmean\n",
    "    elif mode == 'mean':\n",
    "        function = np.mean\n",
    "\n",
    "    for mode in column_list:\n",
    "        values_per_worker = values_per_mode[mode].values\n",
    "        value = function(values_per_worker)\n",
    "        values_per_with_bca_conf_intervals['value'].append(value)\n",
    "        value_conf_interval = res_bootstrap.bootstrap_ci(values_per_worker, f=function, b=10000, ci_method=\"bca\")\n",
    "\n",
    "        # calculate the distance between the summary statistic and the lower and upper bounds of the confidence intervals\n",
    "        left_delta = abs(value - value_conf_interval[0])\n",
    "        right_delta = abs(value_conf_interval[1] - value)\n",
    "        values_per_with_bca_conf_intervals['conf_interval_delta_from_value'].append((left_delta, right_delta))\n",
    "\n",
    "    return pd.DataFrame(values_per_with_bca_conf_intervals)\n",
    "\n",
    "# Returns an altair graph for the percentage differences + confidence interval graph\n",
    "def get_conf_interval_graph(time_per_mode_with_bca_intervals, axis_domain, percent=False):\n",
    "    axis_limits = alt.Scale(domain=axis_domain,zero=False)\n",
    "        \n",
    "    if percent:\n",
    "        text_encoding = alt.Text('value:Q', format=\".2%\")\n",
    "        x_encoding = alt.X('value:Q', title=None, scale=axis_limits, axis=alt.Axis(format='%'))\n",
    "    else:\n",
    "        text_encoding = alt.Text('value:Q', format=\".2f\")\n",
    "        x_encoding = alt.X('value:Q', title=None, scale=axis_limits)\n",
    "        \n",
    "    points = alt.Chart().transform_calculate(\n",
    "        percent_diff=alt.datum.percent_diff\n",
    "    ).mark_point(\n",
    "        filled=True,\n",
    "        color='black'\n",
    "    ).encode(\n",
    "        x=x_encoding,\n",
    "        color=alt.Color('mode:N', legend=None),\n",
    "    )\n",
    "\n",
    "    # generate the error bars\n",
    "    errorbars = points.mark_rule(size=1).encode(\n",
    "        x='xmin:Q',\n",
    "        x2='xmax:Q',\n",
    "        color=alt.Color('mode:N', legend=None)\n",
    "    ).transform_calculate(\n",
    "        xmin='datum.value-datum.conf_interval_delta_from_value[0]',\n",
    "        xmax='datum.value+datum.conf_interval_delta_from_value[1]'\n",
    "    )\n",
    "\n",
    "    text = points.mark_text(\n",
    "        align='center',\n",
    "        baseline='middle',\n",
    "        dy = -7,\n",
    "        dx = 0,\n",
    "        fontSize=8\n",
    "    ).encode(\n",
    "        text=text_encoding\n",
    "    )\n",
    "\n",
    "    graph = alt.layer(points, errorbars, text).facet(\n",
    "        data=time_per_mode_with_bca_intervals,\n",
    "        row=alt.Row(\n",
    "            'mode:N',\n",
    "            header=alt.Header(\n",
    "    #             titleOrient='bottom',\n",
    "    #             labelOrient='bottom',\n",
    "    #             labelPadding=0,\n",
    "                labelAngle=0,\n",
    "                titlePadding=0,\n",
    "                title=None\n",
    "            ),\n",
    "         sort=['SQL', 'QV', 'Both']\n",
    "        ),\n",
    "    ).configure_facet(\n",
    "        spacing=0,\n",
    "    ).configure_view(\n",
    "        stroke=None,\n",
    "        width=200,\n",
    "    ).properties(\n",
    "    #     title='Mean time per mode',\n",
    "    ).configure_axis(\n",
    "        gridOpacity=0.7\n",
    "    #     orient = \"top\",\n",
    "    )\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc600c-5731-406a-b4c2-fd310b653777",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_time_per_mode_with_bca_conf_intervals = get_conf_interval_bca(mean_time_per_mode, 'median', modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79250a7d-aa6a-4767-8ea3-831259059ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}